{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_classes import PYKE\n",
    "from helper_classes import Parser\n",
    "from helper_classes import DataAnalyser\n",
    "from helper_classes import PPMI\n",
    "\n",
    "import util as ut\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning DBpedia Embedings with PYKE\n",
    "\n",
    "1. Download drugbank.nq.gz from http://download.bio2rdf.org/#/release/4/drugbank/\n",
    "2. Extract drugbank.nq and locate the file under KGs/Drugbank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL PARAMS\n",
    "K = 45\n",
    "num_of_dims = 50\n",
    "bound_on_iter = 30\n",
    "omega = 0.45557\n",
    "e_release = 0.0414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_root = 'KGs/Drugbank'\n",
    "kg_path = kg_root + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Drugbank is serializedin N-Quads format\n",
    "ut.triple=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Preprocessing  starts ######\n",
      "\n",
      "\n",
      "###### Constructing Inverted Index  starts ######\n",
      "Number of RDF triples: 3146309\n",
      "Number of vocabulary terms:  521363\n",
      "Number of subjects:  421121\n",
      "Constructing Inverted Index  took  41.95017957687378  seconds\n",
      "\n",
      "\n",
      "\n",
      "###### Calculation of PPMIs  starts ######\n",
      "Calculation of PPMIs  took  112.18523621559143  seconds\n",
      "\n",
      "Preprocessing  took  154.30482602119446  seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "storage_path, experiment_folder = ut.create_experiment_folder()\n",
    "\n",
    "parser = Parser(p_folder=storage_path, k=K)\n",
    "\n",
    "parser.set_similarity_measure(PPMI)\n",
    "\n",
    "model = PYKE()\n",
    "\n",
    "analyser = DataAnalyser(p_folder=storage_path)\n",
    "\n",
    "\n",
    "# For the illustration purposes, one can consider only the first 1000 ntriples\n",
    "#holder = parser.pipeline_of_preprocessing(kg_path,bound=10000)\n",
    "# To reproduce the reported results\n",
    "holder = parser.pipeline_of_preprocessing(kg_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Generating Embeddings:  starts ######\n",
      "EPOCH:  0\n",
      "EPOCH:  1\n",
      "EPOCH:  2\n",
      "EPOCH:  3\n",
      "EPOCH:  4\n",
      "EPOCH:  5\n",
      "EPOCH:  6\n",
      "EPOCH:  7\n",
      "EPOCH:  8\n",
      "EPOCH:  9\n",
      "EPOCH:  10\n",
      "EPOCH:  11\n",
      "EPOCH:  12\n",
      "EPOCH:  13\n",
      "EPOCH:  14\n",
      "EPOCH:  15\n",
      "EPOCH:  16\n",
      "EPOCH:  17\n",
      "EPOCH:  18\n",
      "EPOCH:  19\n",
      "EPOCH:  20\n",
      "EPOCH:  21\n",
      "EPOCH:  22\n",
      "EPOCH:  23\n",
      "EPOCH:  24\n",
      "\n",
      " Epoch:  24\n",
      "System energy: -0.03499999999999983\n",
      "Generating Embeddings:  took  691.3569419384003  seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(holder)\n",
    "\n",
    "embeddings = ut.randomly_initialize_embedding_space(vocab_size, num_of_dims)\n",
    "\n",
    "learned_embeddings = model.pipeline_of_learning_embeddings(e=embeddings,\n",
    "                                                           max_iteration=bound_on_iter,\n",
    "                                                           energy_release_at_epoch=e_release,\n",
    "                                                           holder=holder, omega=omega)\n",
    "\n",
    "\n",
    "# To use memory efficiently\n",
    "del holder\n",
    "del embeddings\n",
    "\n",
    "# To save learned embeddings\n",
    "#learned_embeddings.to_csv(storage_path + '/PYKE_50_embd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of resourses with Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421121"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_info = ut.deserializer(path=storage_path, serialized_name='type_info')\n",
    "len(type_info)# denoted as \\mathcal{S} in the paper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index of objects / get type information =>>> s #type o\n",
    "all_types = sorted(set.union(*list(type_info.values())))\n",
    "len(all_types)# denoted as C in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.w3.org/2002/07/owl#DatatypeProperty\n",
      "http://www.w3.org/2002/07/owl#ObjectProperty\n",
      "http://bio2rdf.org/drugbank_vocabulary:Resource\n",
      "http://www.w3.org/2000/01/rdf-schema#Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Drug\n",
      "http://www.w3.org/2002/07/owl#Class\n",
      "http://bio2rdf.org/drugbank_vocabulary:Biotech\n",
      "http://bio2rdf.org/cas_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Indication\n",
      "http://bio2rdf.org/drugbank_vocabulary:Pharmacodynamics\n",
      "http://bio2rdf.org/drugbank_vocabulary:Mechanism-of-action\n",
      "http://bio2rdf.org/drugbank_vocabulary:Toxicity\n",
      "http://bio2rdf.org/drugbank_vocabulary:Absorption\n",
      "http://bio2rdf.org/drugbank_vocabulary:Half-life\n",
      "http://bio2rdf.org/drugbank_vocabulary:Route-of-elimination\n",
      "http://bio2rdf.org/drugbank_vocabulary:Volume-of-distribution\n",
      "http://bio2rdf.org/drugbank_vocabulary:Clearance\n",
      "http://bio2rdf.org/drugbank_vocabulary:Group\n",
      "http://bio2rdf.org/drugbank_vocabulary:Category\n",
      "http://bio2rdf.org/drugbank_vocabulary:Drug-Classification-Category\n",
      "http://bio2rdf.org/atc_vocabulary:Resource\n",
      "http://bio2rdf.org/ahfs_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Synonym\n",
      "http://bio2rdf.org/drugbank_vocabulary:Mixture\n",
      "http://bio2rdf.org/drugbank_vocabulary:Manufacturer\n",
      "http://bio2rdf.org/drugbank_vocabulary:Pharmaceutical\n",
      "http://bio2rdf.org/drugbank_vocabulary:Unit\n",
      "http://bio2rdf.org/drugbank_vocabulary:Dosage\n",
      "http://bio2rdf.org/drugbank_vocabulary:Melting-Point\n",
      "http://bio2rdf.org/drugbank_vocabulary:Source\n",
      "http://bio2rdf.org/drugbank_vocabulary:Hydrophobicity\n",
      "http://bio2rdf.org/drugbank_vocabulary:Isoelectric-Point\n",
      "http://bio2rdf.org/drugbank_vocabulary:Molecular-Weight\n",
      "http://bio2rdf.org/drugbank_vocabulary:Molecular-Formula\n",
      "http://bio2rdf.org/uspto_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Patent\n",
      "http://bio2rdf.org/drugbank_vocabulary:Target\n",
      "http://bio2rdf.org/drugbank_vocabulary:Target-Relation\n",
      "http://bio2rdf.org/pubmed_vocabulary:Resource\n",
      "http://bio2rdf.org/taxonomy_vocabulary:Resource\n",
      "http://bio2rdf.org/hgnc_vocabulary:Resource\n",
      "http://bio2rdf.org/genatlas_vocabulary:Resource\n",
      "http://bio2rdf.org/genecards_vocabulary:Resource\n",
      "http://bio2rdf.org/genbank_vocabulary:Resource\n",
      "http://bio2rdf.org/gi_vocabulary:Resource\n",
      "http://bio2rdf.org/uniprot_vocabulary:Resource\n",
      "http://bio2rdf.org/skos_vocabulary:Resource\n",
      "http://bio2rdf.org/pfam_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Affected-organism\n",
      "http://bio2rdf.org/dpd_vocabulary:Resource\n",
      "http://bio2rdf.org/kegg_vocabulary:Resource\n",
      "http://bio2rdf.org/ndc_vocabulary:Resource\n",
      "http://bio2rdf.org/pharmgkb_vocabulary:Resource\n",
      "http://bio2rdf.org/wikipedia_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:International-brand\n",
      "http://bio2rdf.org/drugbank_vocabulary:Name\n",
      "http://bio2rdf.org/drugbank_vocabulary:Enzyme\n",
      "http://bio2rdf.org/drugbank_vocabulary:Enzyme-Relation\n",
      "http://bio2rdf.org/drugbank_vocabulary:Drug-Drug-Interaction\n",
      "http://bio2rdf.org/drugbank_vocabulary:Protein-binding\n",
      "http://bio2rdf.org/drugbank_vocabulary:Food-interaction\n",
      "http://bio2rdf.org/drugbank_vocabulary:Salt\n",
      "http://bio2rdf.org/inchi_vocabulary:Resource\n",
      "http://bio2rdf.org/iuphar_vocabulary:Resource\n",
      "http://bio2rdf.org/gtp_vocabulary:Resource\n",
      "http://bio2rdf.org/chebi_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:Small-molecule\n",
      "http://bio2rdf.org/drugbank_vocabulary:Water-Solubility\n",
      "http://bio2rdf.org/drugbank_vocabulary:LogP\n",
      "http://bio2rdf.org/drugbank_vocabulary:LogS\n",
      "http://bio2rdf.org/drugbank_vocabulary:IUPAC-Name\n",
      "http://bio2rdf.org/drugbank_vocabulary:Traditional-IUPAC-Name\n",
      "http://bio2rdf.org/drugbank_vocabulary:Monoisotopic-Weight\n",
      "http://bio2rdf.org/drugbank_vocabulary:SMILES\n",
      "http://bio2rdf.org/drugbank_vocabulary:InChI\n",
      "http://bio2rdf.org/drugbank_vocabulary:InChIKey\n",
      "http://bio2rdf.org/drugbank_vocabulary:Polar-Surface-Area-(PSA)\n",
      "http://bio2rdf.org/drugbank_vocabulary:Refractivity\n",
      "http://bio2rdf.org/drugbank_vocabulary:Polarizability\n",
      "http://bio2rdf.org/drugbank_vocabulary:Rotatable-Bond-Count\n",
      "http://bio2rdf.org/drugbank_vocabulary:H-Bond-Acceptor-Count\n",
      "http://bio2rdf.org/drugbank_vocabulary:H-Bond-Donor-Count\n",
      "http://bio2rdf.org/drugbank_vocabulary:PKa-(strongest-acidic)\n",
      "http://bio2rdf.org/drugbank_vocabulary:PKa-(strongest-basic)\n",
      "http://bio2rdf.org/drugbank_vocabulary:Physiological-Charge\n",
      "http://bio2rdf.org/drugbank_vocabulary:Number-of-Rings\n",
      "http://bio2rdf.org/drugbank_vocabulary:Bioavailability\n",
      "http://bio2rdf.org/drugbank_vocabulary:Rule-of-Five\n",
      "http://bio2rdf.org/drugbank_vocabulary:Ghose-Filter\n",
      "http://bio2rdf.org/drugbank_vocabulary:MDDR-Like-Rule\n",
      "http://bio2rdf.org/drugbank_vocabulary:Transporter\n",
      "http://bio2rdf.org/drugbank_vocabulary:Transporter-Relation\n",
      "http://bio2rdf.org/drugbank_vocabulary:Carrier\n",
      "http://bio2rdf.org/drugbank_vocabulary:Carrier-Relation\n",
      "http://bio2rdf.org/drugbank_vocabulary:Caco2-Permeability\n",
      "http://bio2rdf.org/bindingdb_vocabulary:Resource\n",
      "http://bio2rdf.org/pubchem.compound_vocabulary:Resource\n",
      "http://bio2rdf.org/pubchem.substance_vocabulary:Resource\n",
      "http://bio2rdf.org/chemspider_vocabulary:Resource\n",
      "http://bio2rdf.org/pdb_vocabulary:Resource\n",
      "http://bio2rdf.org/drugbank_vocabulary:PKa\n",
      "http://bio2rdf.org/drugbank_vocabulary:Boiling-Point\n"
     ]
    }
   ],
   "source": [
    "vocabulary = ut.deserializer(path=storage_path, serialized_name='vocabulary')\n",
    "for i in all_types:\n",
    "    print(vocabulary[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Type Prediction Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Type Prediction  starts ######\n",
      "K values: [1, 3, 5, 10, 15, 30, 50, 100]\n",
      "##### 1 ####\n",
      "Mean type prediction [0.60998426]\n",
      "##### 3 ####\n",
      "Mean type prediction [0.59381187]\n",
      "##### 5 ####\n",
      "Mean type prediction [0.56270888]\n",
      "##### 10 ####\n",
      "Mean type prediction [0.51363177]\n",
      "##### 15 ####\n",
      "Mean type prediction [0.48338622]\n",
      "##### 30 ####\n",
      "Mean type prediction [0.43191687]\n",
      "##### 50 ####\n",
      "Mean type prediction [0.3957968]\n",
      "##### 100 ####\n",
      "Mean type prediction [0.35052167]\n",
      "Type Prediction  took  7669.856120109558  seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyser.perform_type_prediction(learned_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementation of the type prediction scenario\n",
    "```python\n",
    "@performance_debugger('Type Prediction')\n",
    "def perform_type_prediction(self, df):\n",
    "\n",
    "    def create_binary_type_vector(t_types, a_types):\n",
    "        vector = np.zeros(len(all_types))\n",
    "        i = [a_types.index(_) for _ in t_types]\n",
    "        vector[i] = 1\n",
    "        return vector\n",
    "\n",
    "    def create_binary_type_prediction_vector(t_types, a_types):\n",
    "        vector = np.zeros(len(all_types))\n",
    "        i = [a_types.index(_) for _ in itertools.chain.from_iterable(t_types)]\n",
    "        vector[i] += 1\n",
    "        return vector\n",
    "\n",
    "    # get the types. Mapping from the index of subject to the index of object\n",
    "    type_info = ut.deserializer(path=self.p_folder, serialized_name='type_info')\n",
    "\n",
    "    # get the index of objects / get type information =>>> s #type o\n",
    "    all_types = sorted(set.union(*list(type_info.values())))\n",
    "\n",
    "\n",
    "    # Consider only points with type infos.\n",
    "    e_w_types = df.loc[list(type_info.keys())]\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=101, algorithm='kd_tree', metric='euclidean', n_jobs=-1).fit(\n",
    "        e_w_types)\n",
    "\n",
    "    # Get similarity results for selected entities\n",
    "    df_most_similars = pd.DataFrame(neigh.kneighbors(e_w_types, return_distance=False))\n",
    "\n",
    "    # Reindex the target\n",
    "    df_most_similars.index = e_w_types.index.values\n",
    "\n",
    "    # As sklearn implementation of kneighbors returns the point itself as most similar point\n",
    "    df_most_similars.drop(columns=[0], inplace=True)\n",
    "\n",
    "\n",
    "    # Map back to the original indexes. KNN does not consider the index of Dataframe.\n",
    "    mapper = dict(zip(list(range(len(e_w_types))), e_w_types.index.values))\n",
    "    # The values of most similars are mapped to original vocabulary positions\n",
    "    df_most_similars = df_most_similars.applymap(lambda x: mapper[x])\n",
    "\n",
    "\n",
    "    k_values = [1, 3, 5, 10, 15, 30, 50, 100]\n",
    "\n",
    "    print('K values:',k_values)\n",
    "    for k in k_values:\n",
    "        print('#####', k, '####')\n",
    "        similarities = list()\n",
    "        for _, S in df_most_similars.iterrows():\n",
    "            true_types = type_info[_]\n",
    "            type_predictions = [type_info[_] for _ in S.values[:k]]\n",
    "\n",
    "            vector_true = create_binary_type_vector(true_types, all_types)\n",
    "            vector_prediction = create_binary_type_prediction_vector(type_predictions, all_types)\n",
    "\n",
    "            sim = cosine(vector_true, vector_prediction)\n",
    "            similarities.append(1 - sim)\n",
    "\n",
    "        report = pd.DataFrame(similarities)\n",
    "        print('Mean type prediction', report.mean().values)\n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Cluster Purity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyser.perform_clustering_quality(learned_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Implementation of the cluster purity scenario\n",
    "\n",
    "```python\n",
    "\n",
    "@performance_debugger('Cluster Quality')\n",
    "def perform_clustering_quality(self, df):\n",
    "\n",
    "    def create_binary_type_vector(t_types, a_types):\n",
    "        vector = np.zeros(len(all_types))\n",
    "        i = [a_types.index(_) for _ in t_types]\n",
    "        vector[i] = 1\n",
    "        return vector\n",
    "\n",
    "    type_info = ut.deserializer(path=self.p_folder, serialized_name='type_info')\n",
    "\n",
    "    # get all unique types, i.e. all o : (s,#type,o) \\in KG\n",
    "    all_types = sorted(set.union(*list(type_info.values())))\n",
    "\n",
    "    # get only those resources that have type information\n",
    "    df_only_subjects = df.loc[list(type_info.keys())]\n",
    "\n",
    "    # Apply clustering\n",
    "    df_only_subjects = self.pseudo_label_HDBSCAN(df_only_subjects, min_cluster_size=26, min_samples=29)\n",
    "\n",
    "    clusters = pd.unique(df_only_subjects.labels)\n",
    "\n",
    "    sum_purity = 0\n",
    "    for c in clusters:\n",
    "\n",
    "        valid_indexes_in_c = df_only_subjects[df_only_subjects.labels == c].index.values\n",
    "\n",
    "        sum_of_cosines = 0\n",
    "\n",
    "        print('##### CLUSTER', c, ' #####')\n",
    "\n",
    "        for i in valid_indexes_in_c:\n",
    "\n",
    "            # returns a set of indexes\n",
    "            types_i = type_info[i]\n",
    "\n",
    "            vector_type_i = create_binary_type_vector(types_i, all_types)\n",
    "\n",
    "            for j in valid_indexes_in_c:\n",
    "                types_j = type_info[j]\n",
    "                vector_type_j = create_binary_type_vector(types_j, all_types)\n",
    "\n",
    "                sum_of_cosines += 1 - cosine(vector_type_i, vector_type_j)\n",
    "\n",
    "        purity = sum_of_cosines / (len(valid_indexes_in_c) ** 2)\n",
    "\n",
    "        sum_purity += purity\n",
    "\n",
    "    mean_of_scores = sum_purity / len(clusters)\n",
    "    print('Mean of cluster purity', mean_of_scores)\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pl2vec)",
   "language": "python",
   "name": "pl2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
